{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as b\n",
    "import urllib as url #if you are using python3+ version, import urllib.request\n",
    "import requests\n",
    "from urllib.request import urlopen as uReq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixe = \"https://www.lnr.fr/\"\n",
    "# acces aux pages des saisons\n",
    "saison_wiki = [\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14524&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14523&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14522&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14519&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14520&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14521&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14528&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14529&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14530&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14534&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=14535&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=18505&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=21642&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=24725&day=all\",\n",
    "    \"/rugby-top-14/calendrier-resultats-rugby-top-14?season=27591&day=all\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saison pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saison est la variable globale qui contient toute les informations de toutes les saisons\n",
    "saison = []\n",
    "for w in saison_wiki:\n",
    "    requete = requests.get(fixe +w)\n",
    "    page = requete.content\n",
    "    soup = b(page)\n",
    "\n",
    "    wiki_temp = []\n",
    "    journee_name = []\n",
    "    for i in (soup.findAll(\"section\", {\"class\": \"block block-lnr-custom block-lnr-custom-calendar-results-filter\"})[0].\n",
    "         findAll(\"span\", {\"class\": \"field-content\"}))[15:]:\n",
    "        wiki_temp.append(i.a[\"href\"])\n",
    "        journee_name.append(i.a[\"data-title\"])\n",
    "\n",
    "    journee_n = 0\n",
    "    for j in wiki_temp:\n",
    "        requete = requests.get(fixe+j)\n",
    "        page = requete.content\n",
    "        soup = b(page)\n",
    "        container = soup.findAll(\"div\", {\"class\":\"day-results-table\"})\n",
    "\n",
    "        journee = []\n",
    "        for match in container[0].findAll(\"tr\",{\"class\": 'info-line after'}):\n",
    "            list_info = [i.text for i in (match.findAll(\"span\",{\"format-full\"}))[:-1]]\n",
    "            list_score = match.find(\"td\",{\"cell-score\"}).text.strip().split(\"-\")\n",
    "            list_score.append((match.find(\"td\",{\"cell-bonus-a\"}).text.strip(\"\\n\")))\n",
    "            list_score.append((match.find(\"td\",{\"cell-bonus-b\"}).text.strip(\"\\n\")))\n",
    "            match_list = [journee_name[journee_n]] +list_info + list_score\n",
    "            saison.append(match_list)\n",
    "\n",
    "        for match in container[0].findAll(\"tr\",{\"class\": 'info-line after table-hr'}):\n",
    "            list_info = [i.text for i in (match.findAll(\"span\",{\"format-full\"}))[:-1]]\n",
    "            list_score = match.find(\"td\",{\"cell-score\"}).text.strip().split(\"-\")\n",
    "            list_score.append((match.find(\"td\",{\"cell-bonus-a\"}).text.strip(\"\\n\")))\n",
    "            list_score.append((match.find(\"td\",{\"cell-bonus-b\"}).text.strip(\"\\n\")))\n",
    "            match_list = [journee_name[journee_n]] +list_info + list_score\n",
    "            saison.append(match_list)\n",
    "        journee_n +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"saison - journee\", \"date\",\"equipe_d\", \"equipe_e\", \"score_d\", \"score_e\", \"bonus_d\", \"bonus_e\"]\n",
    "data = pd.DataFrame(saison,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_saison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"score_d\"] = data[\"score_d\"].astype(int)\n",
    "# data.groupby(\"equipe_d\").agg({\"score_d\": \"sum\"}).sort_values(by = \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n",
      "pas la bonne taille\n"
     ]
    }
   ],
   "source": [
    "classement = []\n",
    "wiki_temp = [x[\"href\"] for x in soup_class.find(\"div\", {\"class\": \"tabs-content\"}).findAll(\"a\", {\"class\": \"filter\"})[:10]]\n",
    "\n",
    "for w in wiki_temp:\n",
    "    requete_class = requests.get(fixe + w)\n",
    "    page_class = requete_class.content\n",
    "    soup_class = b(page_class)\n",
    "\n",
    "    wiki_temp_class = []\n",
    "    journee_name_class = []\n",
    "    for i in soup_class.find(\"div\", {\"class\": \"tabs-content\"}).findAll(\"a\", {\"class\": \"filter\"})[10:]:\n",
    "    #     i.findAll(\"span\", {\"class\": \"field-content\"})[15:]\n",
    "        wiki_temp_class.append(i[\"href\"])\n",
    "        journee_name_class.append(i[\"data-title\"])\n",
    "    \n",
    "    \n",
    "    p = 1\n",
    "\n",
    "    for k,j in enumerate(wiki_temp_class):\n",
    "        requete = requests.get(fixe+j)\n",
    "        page = requete.content\n",
    "        soup_class = b(page)\n",
    "        for x in range(14):\n",
    "            try:\n",
    "                team = []\n",
    "                team.append(p)\n",
    "                team.append(journee_name_class[k])\n",
    "\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field views-field-field-ranking\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-points\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field views-field-field--quipe\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-nbmatchsplayed\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-won\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-draws\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-lost\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-bonus\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-pointsscored\"})[x].text.strip())\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-pointsconceded\"})[x].text.strip())\n",
    "\n",
    "                team.append(soup_class.find(\"div\", {\"class\": \"scroll-wrapper\"}).findAll(\"td\", {\"class\": \"views-field-field-diff\"})[x].text.strip()[1:])\n",
    "\n",
    "\n",
    "                classement.append(team)\n",
    "            except:\n",
    "                None\n",
    "        p+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_class = [\"journee\",\"journee_nom\", \"classement\", \"nb_pts\",\"equipe\",\"nb_matchs_joues\",\"victoire\",\"nul\", \"defaite\", \"bonus\", \"pts_marques\",\"pts_pris\",\"ga\"]\n",
    "pd.DataFrame(classement,columns = col_class).to_csv(\"data_classement.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
